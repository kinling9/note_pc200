# 图形处理器：数据级并行

## GPU历史

### 统一处理器阵列

- 可扩展性好
- 资源利用率高
  - 流水线
- 适应图形API的新发展
- 实现通用计算
  - 计算映射

## GPU编程的发展

- GPGPU(General Purpose computation on GPU)
- 使用并行编程语言和API（CUDA、OpenCL等）
- 适用于大规模数据并行问题


> 任务 计算y = ax + y
### 串行
``` c++
void saxpy_serial(int n, float a, float *x, float *y) {
  for (int i = 0; i < n; ++i)
    y[i] = a * x[i] + y[i];
}
// Invoke serial SAXPY kernel
saxpy_serial(n, 2.0, x, y);

```
### CUDA
```C++
__global__
void saxpy_kernel(int n, float a, float *x, float *y) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  if(i < n) y[i] = a * x[i] + y[i];
}
// Invoke parallel SAXPY kernel (256 threads per block)
int nblocks = (n + 255) / 256;
saxpy_kernel<<<nblocks, 256>>>(n, 2.0, x, y);
```
#### kernel
- 由GPU执行的函数
- 细粒度：数据并行

#### 程序结构
```mermaid
graph LR
A[Grid] --> B[Block] --> C[Thread];
```
> 每个线程块不超过1024个线程

### OpenCL

``` c++
__kernel
void saxpy_kernel(int n, float a,
__global float *x,
__global float *y) {
  int i = get_global_id(0);
  if(i < n) y[i] = a*x[i] + y[i];
}
```

```mermaid
graph LR
A[NDRange] --> B[Work item] --> C[Workgroup];
```

## NVIDIA GPU计算结构
1. GPU SIMD 对于分支指令，不同的分支是交替执行的